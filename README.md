[English](./README.md) [‰∏≠Êñá](./README_Chinese.md)    [ÂÜ∞Èâ¥Â§ßÊ®°ÂûãËØÑÊµãÂπ≥Âè∞ËÆøÈóÆÂÖ•Âè£](https://bjllm.com/)

<div align="center">
  <h2><b> Towards Personalized Evaluation of Large Language Models with An Anonymous Crowd-Sourcing Platform (TheWebConf2024) </b></h2>
</div>

---
<p align="center" width="100%">
<a href="" target="_blank"><img src="https://github.com/user-attachments/assets/7852bedc-f7cd-4b49-8064-ee3f578881a8" alt="WriteGPT" style="width: 60%; min-width: 300px; display: block; margin: auto;"></a>
</p>

>
> üôã Please let us know if you find out a mistake or have any suggestions!
> 
> üåü If you find this resource helpful, please consider to star this repository and cite our research:

```
@inproceedings{cheng2024towards,
  title={Towards Personalized Evaluation of Large Language Models with An Anonymous Crowd-Sourcing Platform},
  author={Cheng, Mingyue and Zhang, Hao and Yang, Jiqian and Liu, Qi and Li, Li and Huang, Xin and Song, Liwei and Li, Zhi and Huang, Zhenya and Chen, Enhong},
  booktitle={Companion Proceedings of the ACM on Web Conference 2024},
  pages={1035--1038},
  year={2024}
}
```


## Project Overview

Bingjian Large Model Evaluation Platform is an anonymous crowd-sourcing platform dedicated to providing users with personalized question customization and large model performance evaluation. Through this platform, users can submit test tasks, compete with various models, explore the limits of model capabilities, and support research and development.

---

## Platform Features

- **Anonymous Competitions**: Users can anonymously submit questions, and the platform assigns models to compete, ensuring fairness and objectivity.
- **Personalized Question Customization**: Allows users to submit customized questions to meet diverse evaluation needs.
- **Multi-Model Support**: Built-in support for multiple large models, covering mainstream natural language processing tasks, and supporting multi-language and multimodal evaluations.
- **Data Analysis**: Automatically generates visualized evaluation reports, helping users quickly understand model performance.

---

## Access the Platform

üëâ [Click here to visit the Bingjian Large Model Evaluation Platform](https://bjllm.com)

---

## Usage Guide

### 1. Register and Log In
- Visit [Bingjian Large Model Evaluation Platform](https://bjllm.com).
- Register for a new account or log in with an existing one.

### 2. Submit Questions
- On the platform's homepage, click [**"Model Arena"**](https://bjllm.com/model-arena).
- Select the task type (e.g., generation, discrimination) and fill in the question details .


### 3. View Results
- After the large model provides an answer, users are required to rate the response. 
- The platform will then aggregate all user ratings to create a leaderboard for the large model, and visualize both user profiles and model profiles.
---

## FAQ

### Q: What types of tasks does the platform support?  
A: Currently supported tasks include, but are not limited to:
   - Text generation
   - Text classification
   - Question answering
   - Translation
   - Summarization

### Q: How does the platform ensure fair and anonymous evaluation?  
A: During competitions, all model identity information is masked, and evaluations are based solely on results.

---

## Acknowledgments

We thank all developers and users who have supported the Bingjian Large Model Evaluation Platform. Your involvement is the driving force for our continuous improvement!

---

**üëâ Quick Access**: [Bingjian Large Model Evaluation Platform](https://bjllm.com)  
**üìß Contact Us**: bingjian@ustc.edu.cn  
